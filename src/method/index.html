<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Dynamic Worksite Models - Method</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="icon" type="image/png" href="/images/logo_components_color_2x_web_48dp.png">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto+Mono">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500">
    <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
    <link rel="stylesheet" href="/assets/method/index.css">
    <script src="/ready.js"></script>
  </head>
  <body class="mdc-typography">

    <header class="mdc-toolbar mdc-toolbar--fixed">
      <div class="mdc-toolbar__row">
        <section class="mdc-toolbar__section mdc-toolbar__section--align-start">
          <span class="mdc-toolbar__title mdc-toolbar-title catalog-title">
            <a href="/" title="Home">Dynamic Worksite Models</a>
          </span>
        </section>
        <section class="mdc-toolbar__section mdc-toolbar__section--align-end">
          <div>
            <nav id="toolbar-tab-bar" class="mdc-tab-bar custom-tab-bar-in-toolbar mdc-tab-bar-upgraded">
              <a class="mdc-tab mdc-ripple-upgraded mdc-tab mdc-ripple-upgraded mdc-tab mdc-ripple-upgraded--foreground-activation mdc-tab--active" href="/method">Method</a>
              <a class="mdc-tab mdc-ripple-upgraded" href="/results">Results</a>
              <a class="mdc-tab mdc-ripple-upgraded" href="/robot">Robot</a>
              <a class="mdc-tab mdc-ripple-upgraded" href="/dataset">Dataset</a>
              <span class="mdc-tab-bar__indicator"></span>
            </nav>
          </div>
        </section>
      </div>
    </header>

    <main class="mdc-toolbar-fixed-adjust">
      <section class="content mdc-layout-grid">
        <div class="demo-container ">
          <div class="mdl-cell mdl-cell--2-col mdl-cell--hide-tablet mdl-cell--hide-phone"></div>
          <div class="demo-content mdl-color--white mdl-shadow--4dp content mdl-color-text--grey-800">
            <h1 class="mdc-typography--headline4">Facilitating Dynamic Worksite Models with Mobile Robots</h1>
              <p class="mdc-typography--body1">
                Automation in construction and facility management could significantly improve efficiency and productivity throughout the lifecycle of modern facilities. However, for robots and autonomous systems to operate in effectively in dynamic and unstructured environments such as a construction sites, they must be able to infer or obtain a semantic model of the environment.
              </p>
              <p class="mdc-typography--body1">
                Previous efforts in Civil Engineering and Robotics have focused on developing static maps of the environment, often neglecting the possibility that objects can be moved. This project investigates how information from mobile robots can be used to dynamically update an existing model of the building environment with semantic-rich information. We develop a new 2D-3D computer vision to detect and localize common building site objects, using RGB-D frames. We then propose using a multi-object Kalman filter to track objects across successive RGB-D frames to filter false-positive detections and refine position estimartes. The proposed system is validated using data collected with a purpose-built mobile robot.
              </p>

              <!-- Figure 1 -->
              <div class="mdc-layout-grid">
                <div class="mdc-layout-grid__inner">
                  <div class="mdc-card figure-card mdc-layout-grid__cell mdc-layout-grid__cell--span-12 mdc-shadow--2dp">
                    <figure class="mdc-card__media padded">
                      <img src="images/banner-title.png" alt="" />
                    </figure>
                    <div class="caption">
                      <p class="mdc-typography--body2 mdc-typography--caption">Updating worksite models with mobile robots. Data is collected using a SLAM-enabled mobile robot with RGB-D sensors. Images from the mobile robot vision system is analysed with our 2D-3D computer vision algorithm. Objects are added and removed from the building information model in real-time</p>
                    </div>
                  </div>
                </div>
              </div>

            <h2 class="demo-title mdc-typography--headline6">Framework</h2>
              <p class="mdc-typography--body1">
                We start by proposing a generic framework for updating building information models using mobile robots. In this framework, each mobile robot obtains information about its environment using a combination of LiDAR and RGB-D cameras. An object recognition algorithm is used to detect objects in the field-of-view of the mobile robot and determine the position of each object relative to the mobile robot. The global position of the mobile robot is estimated using a localization algorithm such as Adaptive Monte Carlo Localization (AMCL) or Continuous-Time SLAM. An object tracking and global object localization layer estimates the global positions of detected objects, and filters false-positive detections. Information is broadcasted to the building information model where is used to dynamically update the model.
              </p>

              <!-- Figure 2: Theoretical framework -->
              <div class="mdc-layout-grid">
                <div class="mdc-layout-grid__inner">
                  <div class="mdc-card figure-card mdc-layout-grid__cell mdc-layout-grid__cell--span-12 mdc-shadow--2dp">
                    <figure class="mdc-card__media padded">
                      <img src="images/framework.png" alt="The theoretical framework" />
                    </figure>
                    <div class="caption">
                      <p class="mdc-typography--body2 mdc-typography--caption">The proposed computational framework</p>
                    </div>
                  </div>
                </div>
              </div>

            <h2 class="demo-title mdc-typography--headline6">2D-3D Object Detection Algorithm</h2>
              <p class="mdc-typography--body1">
                The core component of the proposed system is a computer vision algorithm capable of classifying and localizing objects of interest in images captured by a camera on the mobile robot. We notice that 2D object detectors can easily detect a range of worksite objects, using RGB images. 
              </p>

              <!-- Figure 2: Theoretical framework -->
              <div class="mdc-layout-grid">
                <div class="mdc-layout-grid__inner">
                  <div class="mdc-card figure-card mdc-layout-grid__cell mdc-layout-grid__cell--span-8 mdc-shadow--2dp">
                    <figure class="mdc-card__media">
                      <img src="images/boxes2d.png" alt="The theoretical framework" />
                    </figure>
                    <div class="caption">
                      <p class="mdc-typography--body2 mdc-typography--caption">2D object detection and instance segmentation with the Mask R-CNN object detector. Object detection with a 2D framework like Mask R-CNN is fast and accurate, thanks to recent advances in computer vision and graphics hardware.</p>
                    </div>
                  </div>
                </div>
              </div>

              <p class="mdc-typography--body1">
                However, to automatically update a spatial model, the position of each object in 3D space must be obtained. We find that the depth of the object can be estimated using the median point depth inside bounding box. The bounding box can then be projected into 3D space to obtain a rough 3D model of each object
              </p>

              <div class="mdc-layout-grid">
                <div class="mdc-layout-grid__inner">
                  <div class="mdc-card figure-card mdc-layout-grid__cell mdc-layout-grid__cell--span-12 mdc-shadow--2dp">
                    <figure class="mdc-card__media padded">
                      <img src="images/voxels.png" alt="The theoretical framework" />
                    </figure>
                    <div class="caption">
                      <p class="mdc-typography--body2 mdc-typography--caption">Voxel models of worksite objects, generated using the RGB-D image.</p>
                    </div>
                  </div>
                </div>
              </div>

              <p class="mdc-typography--body1">
                We propose a novel extension to Mask R-CNN, which utilized 2D and 3D information to prediction to position of worksite objects in 3D space. The model uses a 3D CNN, similar to VoxNet, to process information from the 3D representation of each detected object. This information is combined with 2D features from Mask R-CNN, to predict the size and position of each object.
              </p>

              <!-- Figure 3: Neural Network -->
              <div class="mdc-layout-grid">
                <div class="mdc-layout-grid__inner">
                  <div class="mdc-card figure-card mdc-layout-grid__cell mdc-layout-grid__cell--span-12 mdc-shadow--2dp">
                    <figure class="mdc-card__media padded">
                      <img src="images/cnn.png" alt="The theoretical framework" />
                    </figure>
                    <div class="caption">
                      <p class="mdc-typography--body2 mdc-typography--caption">Architecture of the proposed defect detection network. Numbers denote spatial resolution and channels. Arrows denote either convolution, deconvolution, or fully connected layers as can be inferred from context (convolution preserves spatial dimension while deconvolution increases it). All convolution layers are 3×3, except the output convolution layer which is 1×1. Deconvolution layers are 2×2 with stride 2. The ReLU activation function is used in hidden layers.</p>
                    </div>
                  </div>
                </div>
              </div>

              <p class="mdc-typography--body1">
                When deployed to the mobile robot, the trained system can be used to detect objects, and automatically add them to a geometric model of the environment
              </p>

              <!-- Figure 6: Depth Masks -->
              <div class="mdc-layout-grid">
                <div class="mdc-layout-grid__inner">
                  <div class="mdc-card figure-card mdc-layout-grid__cell mdc-layout-grid__cell--span-12 mdc-shadow--2dp">
                    <figure class="mdl-card__media">
                      <video controls autoplay class="stretch">
                        <source src="videos/combined.webm">
                        Your browser does not support the video tag.
                      </video>
                    </figure>
                    <div class="caption">
                      <p class="mdc-typography--body2 mdc-typography--caption">Mobile robot recognizing objects. Note, that several false positive-detections lead to incorrect updates</p>
                    </div>
                  </div>
                </div>
              </div>

              <h2 class="demo-title mdc-typography--headline6">Object Association and Tracking</h2>
                <p class="mdc-typography--body1">
                 In general, it is inappropriate to directly update a building information model using predictions from an object detector, as false detections tend to occur with a non-trivial probability. To overcome this issue, a Kalman filter is used to track the position of objects across successive camera frames. The Kalman filter has the following important features that the proposed system can benefit from:
                </p>
                <ul class="mdc-typography--body1">
                  <li>Correction of the predicted position based on new measurements</li>
                  <li>Reduction of false-positive detections introduced by the object detector</li>
                  <li>Association of multiple objects to their tracks</li>
                </ul>
                <p class="mdc-typography--body1">
                Objects are currently tracked in the image coordinate system. Future work will investigate tracking objects a global three dimensional coordinate system. The Kalman filter is initialized using a constant velocity model.
                </p>

              <!-- Figure 6: <! Association -->
              <div class="mdc-layout-grid">
                <div class="mdc-layout-grid__inner">
                  <div class="mdc-card figure-card mdc-layout-grid__cell mdc-layout-grid__cell--span-12 mdc-shadow--2dp">
                    <figure class="mdc-card__media">
                      <img src="images/association.png" alt="The theoretical framework" />
                    </figure>
                    <div class="caption">
                      <p class="mdc-typography--body2 mdc-typography--caption">
                        Associate of detections to tracks
                    </p>
                    </div>
                  </div>
                </div>
              </div>

            <h2 class="demo-title mdc-typography--headline6">Paper</h2>
            <img src="images/paper.png" style="width: 90%;"></img>
            <p class="mdc-typography--body1">
              A 2D-3D Object Detection System for Updating Building Information Models with Mobile Robots <br>
              M. Ferguson, K. H. Law <br>
              <a href="#" title="Automation in Construction Paper">[Coming Soon]</a>

            <h2 class="demo-title mdc-typography--headline6">Source Code</h2>
            <p class="mdc-typography--body1">
              SurfaceNet Source Code [<a href="#" title="Automation in Construction Paper">Coming Soon</a>]<br>
              Mobile Robot Source Code [<a href="#" title="Automation in Construction Paper">Coming Soon</a>]<br>
          </div>
        </div>
      </section>
    </main>

    <script src="/assets/material-components-web.js" async></script>
    <script>
      demoReady(function() {
        var btns = document.querySelectorAll('.mdc-button:not([data-demo-no-js])');
        for (var i = 0, btn; btn = btns[i]; i++) {
          mdc.ripple.MDCRipple.attachTo(btn);
        }

        document.getElementById('toggle-disabled').addEventListener('change', function() {
          var isDisabled = this.checked;
          [].forEach.call(document.querySelectorAll('button'), function(button) {
            button.disabled = isDisabled;
          });
        });
      });
    </script>
  </body>
</html>
